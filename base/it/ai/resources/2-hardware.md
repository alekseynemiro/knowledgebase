---
slug: hardware
title: Железо для ИИ
description: Небольшие заметки об аппаратном обеспечении для создания и использования ИИ.
tags:
  - Hardware
  - AI
  - LLM
  - Large Language Models
  - Machine Learning
  - GPU
  - CPU
  - RAM
  - VRAM
  - HDD
  - SSD
  - ИИ
  - Большие языковые модели
  - Железо
---

# Железо для ИИ

Существует два основных направления работы с большими языковыми моделями (LLM): **[Inference](../llm/glossary.md)** (генерация, вывод) и **[Fine-Tuning](../llm/glossary.md)** (тонкая настройка, обучение).

Если для генерации (inference) количество ресурсов больше влияет на комфортную скорость и точность моделей, то для **Fine-Tuning** требования гораздо выше, особенно к **GPU**.

[llama.cpp](../llm/llama-cpp) позволяет использовать процессор (**CPU**) и оперативную память (**RAM**), если ресурсов графического процессора (**GPU**) недостаточно.

GPU предпочтительнее CPU. Во всех случаях, чем больше ресурсов, тем лучше.

В идеале, лучше использовать профессиональное оборудование, потому что оно предназначено для длительной безотказной работы на высоких нагрузках.

## GPU (Graphics processing unit — графический процессор)

По состоянию на 2025 год продукция **NVIDIA** будет предпочтительнее во всех случаях.

Особое внимание следует уделить следующим моментам:

* **Tensor cores** (тензорные ядра) — специальные ядра, обеспечивающие динамические вычисления и вычисления со смешанной точностью.
* **CUDA** (**Compute Unified Device Architecture**) ядра — специализированные ядра, предназначенные для параллельных вычислений.
* **Video Random Access Memory** (**VRAM**) — 16/24 GB или больше.

Также обратите внимание на следующее:

* Потребляемая мощность.
* Система отвода тепла.
